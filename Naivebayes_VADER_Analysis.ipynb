{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in c:\\users\\rupal\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.42.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>TextBlobAnalysis</th>\n",
       "      <th>VADERAnalysis</th>\n",
       "      <th>TextBlobAnalysis_Val</th>\n",
       "      <th>VADERAnalysis_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>FWolfenbuttel</td>\n",
       "      <td>Hannover, Deutschland</td>\n",
       "      <td>Jojo Due to the Corona Virus the stalk market ...</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>-0.06250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.851</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>665</td>\n",
       "      <td>aClassicLiberal</td>\n",
       "      <td>Digital Nomad (Tampa Bay)</td>\n",
       "      <td>This is for Italy Ive a long thread on the Co...</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.14375</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>327</td>\n",
       "      <td>PresidentKovach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Im out yall she got me before corona could lma...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>669</td>\n",
       "      <td>httpsjhey</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>Me in 2050 telling my grandkids about Corona V...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>worom_z</td>\n",
       "      <td>Federal Capital Territory, Nig</td>\n",
       "      <td>I just noticed corona virus has emoji</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             user                        location  \\\n",
       "406         406    FWolfenbuttel           Hannover, Deutschland   \n",
       "665         665  aClassicLiberal      Digital Nomad (Tampa Bay)    \n",
       "327         327  PresidentKovach                             NaN   \n",
       "669         669        httpsjhey                         Jamaica   \n",
       "971         971          worom_z  Federal Capital Territory, Nig   \n",
       "\n",
       "                                                Tweets  Subjectivity  \\\n",
       "406  Jojo Due to the Corona Virus the stalk market ...        0.3375   \n",
       "665   This is for Italy Ive a long thread on the Co...        0.4125   \n",
       "327  Im out yall she got me before corona could lma...        0.0000   \n",
       "669  Me in 2050 telling my grandkids about Corona V...        0.0000   \n",
       "971             I just noticed corona virus has emoji         0.0000   \n",
       "\n",
       "     Polarity  Positive  Negative  Neutral  compound TextBlobAnalysis  \\\n",
       "406  -0.06250     0.000     0.149    0.851   -0.2732         Negative   \n",
       "665   0.14375     0.126     0.000    0.874    0.3182         Positive   \n",
       "327   0.00000     0.000     0.000    1.000    0.0000          Neutral   \n",
       "669   0.00000     0.000     0.000    1.000    0.0000          Neutral   \n",
       "971   0.00000     0.000     0.000    1.000    0.0000          Neutral   \n",
       "\n",
       "    VADERAnalysis  TextBlobAnalysis_Val  VADERAnalysis_Val  \n",
       "406      Negative                     0                  0  \n",
       "665      Positive                     2                  2  \n",
       "327       Neutral                     1                  1  \n",
       "669       Neutral                     1                  1  \n",
       "971       Neutral                     1                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "df=pd.read_csv('twitterMining.csv')\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data for VADERAnalysis_Val\n",
    "X, y = df['Tweets'], df['VADERAnalysis_Val']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # use spacy to filter out noise\n",
    "    tokens = [token.lemma_.lower() \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are greater than 2 characters long\n",
    "                                    token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve selected pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab \n",
    "                                    token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop and # get rid of tokens that are stop words\n",
    "                                    not token.is_currency # get rid of tokens that denote currencies\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         toppe corona\n",
       "1    trend continue rare day march delhi well weath...\n",
       "2     crush agree date play away mr oxygen problem don\n",
       "3          balanced view forget check study retired dr\n",
       "4                              guys corona invade hell\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(Xtrain)\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtrain = pd.Series(clean_corpus)\n",
    "Xtrain.head()\n",
    "\n",
    "\n",
    "corpus = nlp.pipe(Xtest)\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtest = pd.Series(clean_corpus)\n",
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        binary=False,\n",
    "        use_idf=True, smooth_idf=True, # idf  - with smoothing\n",
    "        norm='l2', # tfidf - l2 norm\n",
    "        lowercase=True, stop_words='english', \n",
    "        #token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', \n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1)\n",
    "    )),\n",
    "    ('nb', MultinomialNB(\n",
    "        fit_prior=True, # learn class prior-probabilities from data\n",
    "        class_prior=None # none - go with whatever fit-prior says\n",
    "    ))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__sublinear_tf':['True','False'], \n",
    "   'nb__alpha': [0.00002, 0.000002, 0.002, 0.0000002,0.2, 0.1,0.001]}\n",
    "\n",
    "gscv = GridSearchCV(clf, param_grid, cv=4, return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        stri...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'nb__alpha': [2e-05, 2e-06, 0.002, 2e-07, 0.2, 0.1,\n",
       "                                       0.001],\n",
       "                         'tfidf__sublinear_tf': ['True', 'False']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words='english', strip_accents=None,\n",
      "                                 sublinear_tf='True',\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('nb',\n",
      "                 MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.55375 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'True'} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'mean_fit_time': array([0.01820195, 0.0084759 , 0.00797743, 0.00798017, 0.00773883,\n",
      "       0.00772649, 0.00796634, 0.00774175, 0.00798589, 0.00771737,\n",
      "       0.00723094, 0.00847739, 0.00822794, 0.00747997]), 'std_fit_time': array([1.65945672e-02, 4.95316004e-04, 2.09466021e-06, 7.02505762e-04,\n",
      "       4.37314238e-04, 4.32537938e-04, 2.25020757e-05, 4.37554523e-04,\n",
      "       3.81236825e-06, 8.12297767e-04, 4.31708056e-04, 4.98712127e-04,\n",
      "       4.31742491e-04, 4.98592861e-04]), 'mean_score_time': array([0.00225383, 0.00199682, 0.001746  , 0.002482  , 0.00224376,\n",
      "       0.00224513, 0.00249267, 0.00248331, 0.00198871, 0.00224292,\n",
      "       0.00199443, 0.00199407, 0.00199479, 0.00199455]), 'std_score_time': array([4.23995968e-04, 1.68903200e-06, 4.31434753e-04, 4.87536683e-04,\n",
      "       4.31673644e-04, 4.35710047e-04, 4.80654250e-04, 4.86925293e-04,\n",
      "       1.74693476e-06, 4.30916783e-04, 3.09714819e-07, 5.43024157e-07,\n",
      "       1.97686242e-07, 1.97686242e-07]), 'param_nb__alpha': masked_array(data=[2e-05, 2e-05, 2e-06, 2e-06, 0.002, 0.002, 2e-07, 2e-07,\n",
      "                   0.2, 0.2, 0.1, 0.1, 0.001, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__sublinear_tf': masked_array(data=['True', 'False', 'True', 'False', 'True', 'False',\n",
      "                   'True', 'False', 'True', 'False', 'True', 'False',\n",
      "                   'True', 'False'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'nb__alpha': 2e-05, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-05, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 2e-06, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-06, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.002, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.002, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 2e-07, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-07, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.1, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.1, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.001, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.001, 'tfidf__sublinear_tf': 'False'}], 'split0_test_score': array([0.535, 0.535, 0.535, 0.535, 0.55 , 0.55 , 0.535, 0.535, 0.55 ,\n",
      "       0.55 , 0.55 , 0.55 , 0.55 , 0.55 ]), 'split1_test_score': array([0.54 , 0.54 , 0.54 , 0.54 , 0.54 , 0.54 , 0.535, 0.535, 0.535,\n",
      "       0.535, 0.535, 0.535, 0.54 , 0.54 ]), 'split2_test_score': array([0.545, 0.545, 0.525, 0.525, 0.555, 0.555, 0.525, 0.525, 0.565,\n",
      "       0.565, 0.56 , 0.56 , 0.56 , 0.56 ]), 'split3_test_score': array([0.555, 0.555, 0.555, 0.555, 0.54 , 0.54 , 0.55 , 0.55 , 0.565,\n",
      "       0.565, 0.555, 0.555, 0.54 , 0.54 ]), 'mean_test_score': array([0.54375, 0.54375, 0.53875, 0.53875, 0.54625, 0.54625, 0.53625,\n",
      "       0.53625, 0.55375, 0.55375, 0.55   , 0.55   , 0.5475 , 0.5475 ]), 'std_test_score': array([0.0073951 , 0.0073951 , 0.01082532, 0.01082532, 0.00649519,\n",
      "       0.00649519, 0.00892679, 0.00892679, 0.01243734, 0.01243734,\n",
      "       0.00935414, 0.00935414, 0.00829156, 0.00829156]), 'rank_test_score': array([ 9,  9, 11, 11,  7,  7, 13, 13,  1,  1,  3,  3,  5,  5])} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Uncomment below to see the results of hyperparameter tuning\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_estimator_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_score_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_params_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.cv_results_, \"\\n\")\n",
    "print (\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475\n",
      "confusion matrix\n",
      "[[39 14 14]\n",
      " [21 33 15]\n",
      " [29 12 23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.58      0.50        67\n",
      "           1       0.56      0.48      0.52        69\n",
      "           2       0.44      0.36      0.40        64\n",
      "\n",
      "    accuracy                           0.48       200\n",
      "   macro avg       0.48      0.47      0.47       200\n",
      "weighted avg       0.48      0.47      0.47       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print(\"confusion matrix\")\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))\n",
    "# TN,FP,FN,TP = metrics.confusion_matrix(y_true=ytest, y_pred=ypred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
