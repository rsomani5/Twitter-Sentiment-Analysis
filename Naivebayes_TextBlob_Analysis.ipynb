{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: spacy in c:\\users\\rupal\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (45.2.0.post20200210)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (45.2.0.post20200210)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.42.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rupal\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.2.0)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>compound</th>\n",
       "      <th>TextBlobAnalysis</th>\n",
       "      <th>VADERAnalysis</th>\n",
       "      <th>TextBlobAnalysis_Val</th>\n",
       "      <th>VADERAnalysis_Val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>819</td>\n",
       "      <td>cyberdyne</td>\n",
       "      <td>Tehran</td>\n",
       "      <td>Backfilling my daily quotient of beer with Cor...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>Gem_N_Eye_Radio</td>\n",
       "      <td>NO-where STL ✈ ATL ✈TUL✈ HTOWN</td>\n",
       "      <td>Wow this CORONA really got yall in an IMPOSSIB...</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>-0.122222</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>Freedom_24_7</td>\n",
       "      <td>United States</td>\n",
       "      <td>Try to defend sticking sticking pork barre...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>586</td>\n",
       "      <td>Cfa89</td>\n",
       "      <td>/\\/¯¯¯¯¯\\/\\   I♥CPT ZA</td>\n",
       "      <td>80s Yeah i mean corona is strictly for 100 or ...</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>757</td>\n",
       "      <td>DanieImcgrogan</td>\n",
       "      <td>CHY NA</td>\n",
       "      <td>Donald trump will literally joke his way into ...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             user                        location  \\\n",
       "819         819        cyberdyne                          Tehran   \n",
       "375         375  Gem_N_Eye_Radio  NO-where STL ✈ ATL ✈TUL✈ HTOWN   \n",
       "415         415     Freedom_24_7                   United States   \n",
       "586         586            Cfa89          /\\/¯¯¯¯¯\\/\\   I♥CPT ZA   \n",
       "757         757   DanieImcgrogan                          CHY NA   \n",
       "\n",
       "                                                Tweets  Subjectivity  \\\n",
       "819  Backfilling my daily quotient of beer with Cor...      0.050000   \n",
       "375  Wow this CORONA really got yall in an IMPOSSIB...      0.733333   \n",
       "415      Try to defend sticking sticking pork barre...      0.000000   \n",
       "586  80s Yeah i mean corona is strictly for 100 or ...      0.593750   \n",
       "757  Donald trump will literally joke his way into ...      0.550000   \n",
       "\n",
       "     Polarity  Positive  Negative  Neutral  compound TextBlobAnalysis  \\\n",
       "819  0.000000     0.000       0.0    1.000    0.0000          Neutral   \n",
       "375 -0.122222     0.275       0.0    0.725    0.5859         Negative   \n",
       "415  0.000000     0.000       0.0    1.000    0.0000          Neutral   \n",
       "586  0.093750     0.196       0.0    0.804    0.2960         Positive   \n",
       "757  0.250000     0.224       0.0    0.776    0.5994         Positive   \n",
       "\n",
       "    VADERAnalysis  TextBlobAnalysis_Val  VADERAnalysis_Val  \n",
       "819       Neutral                     1                  1  \n",
       "375      Positive                     0                  2  \n",
       "415       Neutral                     1                  1  \n",
       "586      Positive                     2                  2  \n",
       "757      Positive                     2                  2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data into a pandas dataframe\n",
    "df=pd.read_csv('twitterMining.csv')\n",
    "df.sample(frac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data\n",
    "X, y = df['Tweets'], df['TextBlobAnalysis_Val']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "Xtrain = Xtrain.copy()\n",
    "Xtest = Xtest.copy()\n",
    "ytrain = ytrain.copy()\n",
    "ytest = ytest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):\n",
    "\n",
    "    # use spacy to filter out noise\n",
    "    tokens = [token.lemma_.lower() \n",
    "                        for token in doc \n",
    "                               if (\n",
    "                                    len(token) >= 2 and # only preserve tokens that are greater than 2 characters long\n",
    "                                    token.pos_ in ['PROPN', 'NOUN', 'ADJ', 'VERB', 'ADV'] and # only preserve selected pos\n",
    "                                    #token.text in nlp.vocab and # check if token in vocab \n",
    "                                    token.is_alpha and # only preserve tokens that are fully alpha (not numeric or alpha-numeric)\n",
    "                                    #not token.is_digit and # get rid of tokens that are fully numeric\n",
    "                                    not token.is_punct and # get rid of tokens that are punctuations\n",
    "                                    not token.is_space and # get rid of tokens that are spaces\n",
    "                                    not token.is_stop and # get rid of tokens that are stop words\n",
    "                                    not token.is_currency # get rid of tokens that denote currencies\n",
    "                                )\n",
    "                   ]\n",
    "\n",
    "    # return cleaned-up text\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         toppe corona\n",
       "1    trend continue rare day march delhi well weath...\n",
       "2     crush agree date play away mr oxygen problem don\n",
       "3          balanced view forget check study retired dr\n",
       "4                              guys corona invade hell\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", disable=['parser', 'ner'])\n",
    "corpus = nlp.pipe(Xtrain)\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtrain = pd.Series(clean_corpus)\n",
    "Xtrain.head()\n",
    "\n",
    "\n",
    "corpus = nlp.pipe(Xtest)\n",
    "clean_corpus = [custom_tokenizer(doc) for doc in corpus]\n",
    "Xtest = pd.Series(clean_corpus)\n",
    "Xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        binary=False,\n",
    "        use_idf=True, smooth_idf=True, # idf  - with smoothing\n",
    "        norm='l2', # tfidf - l2 norm\n",
    "        lowercase=True, stop_words='english', \n",
    "        #token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', \n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1)\n",
    "    )),\n",
    "    ('nb', MultinomialNB(\n",
    "        fit_prior=True, # learn class prior-probabilities from data\n",
    "        class_prior=None # none - go with whatever fit-prior says\n",
    "    ))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'tfidf__sublinear_tf':['True','False'], \n",
    "   'nb__alpha': [0.00002, 0.000002, 0.002, 0.0000002,0.2, 0.1,0.001]}\n",
    "\n",
    "gscv = GridSearchCV(clf, param_grid, cv=4, return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        stri...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'nb__alpha': [2e-05, 2e-06, 0.002, 2e-07, 0.2, 0.1,\n",
       "                                       0.001],\n",
       "                         'tfidf__sublinear_tf': ['True', 'False']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Pipeline(memory=None,\n",
      "         steps=[('tfidf',\n",
      "                 TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.float64'>,\n",
      "                                 encoding='utf-8', input='content',\n",
      "                                 lowercase=True, max_df=1.0, max_features=None,\n",
      "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
      "                                 preprocessor=None, smooth_idf=True,\n",
      "                                 stop_words='english', strip_accents=None,\n",
      "                                 sublinear_tf='True',\n",
      "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                                 tokenizer=None, use_idf=True,\n",
      "                                 vocabulary=None)),\n",
      "                ('nb',\n",
      "                 MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))],\n",
      "         verbose=False) \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0.56875 \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'True'} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'mean_fit_time': array([0.01696372, 0.00798756, 0.00747877, 0.00798446, 0.00798106,\n",
      "       0.00821781, 0.0079869 , 0.00798005, 0.00797832, 0.00747848,\n",
      "       0.00770944, 0.00898647, 0.0082351 , 0.00796747]), 'std_fit_time': array([1.49716905e-02, 1.92214583e-05, 4.97286874e-04, 1.26680555e-05,\n",
      "       6.94078642e-04, 4.14192055e-04, 1.73591813e-05, 9.44315166e-07,\n",
      "       2.79766196e-05, 4.99846101e-04, 4.17849268e-04, 2.32942076e-03,\n",
      "       4.47858513e-04, 1.79234646e-05]), 'mean_score_time': array([0.00249392, 0.00224704, 0.001993  , 0.00198728, 0.00223869,\n",
      "       0.00199467, 0.00249356, 0.00224257, 0.00199556, 0.00324601,\n",
      "       0.00200236, 0.00250155, 0.0019955 , 0.00200999]), 'std_score_time': array([4.96211768e-04, 4.35703915e-04, 2.73077755e-06, 2.50647985e-05,\n",
      "       4.36249889e-04, 2.59810623e-07, 4.98359632e-04, 4.31814915e-04,\n",
      "       2.92001932e-07, 4.32130612e-04, 1.66999408e-05, 5.12137076e-04,\n",
      "       5.02767917e-06, 1.66667206e-05]), 'param_nb__alpha': masked_array(data=[2e-05, 2e-05, 2e-06, 2e-06, 0.002, 0.002, 2e-07, 2e-07,\n",
      "                   0.2, 0.2, 0.1, 0.1, 0.001, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_tfidf__sublinear_tf': masked_array(data=['True', 'False', 'True', 'False', 'True', 'False',\n",
      "                   'True', 'False', 'True', 'False', 'True', 'False',\n",
      "                   'True', 'False'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'nb__alpha': 2e-05, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-05, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 2e-06, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-06, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.002, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.002, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 2e-07, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 2e-07, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.2, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.1, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.1, 'tfidf__sublinear_tf': 'False'}, {'nb__alpha': 0.001, 'tfidf__sublinear_tf': 'True'}, {'nb__alpha': 0.001, 'tfidf__sublinear_tf': 'False'}], 'split0_test_score': array([0.545, 0.545, 0.55 , 0.55 , 0.545, 0.545, 0.55 , 0.55 , 0.58 ,\n",
      "       0.58 , 0.555, 0.555, 0.54 , 0.54 ]), 'split1_test_score': array([0.525, 0.525, 0.525, 0.525, 0.51 , 0.51 , 0.525, 0.525, 0.55 ,\n",
      "       0.55 , 0.525, 0.525, 0.51 , 0.51 ]), 'split2_test_score': array([0.53 , 0.53 , 0.53 , 0.53 , 0.535, 0.535, 0.505, 0.505, 0.55 ,\n",
      "       0.55 , 0.54 , 0.54 , 0.535, 0.535]), 'split3_test_score': array([0.495, 0.495, 0.485, 0.485, 0.515, 0.515, 0.485, 0.485, 0.595,\n",
      "       0.595, 0.56 , 0.56 , 0.515, 0.515]), 'mean_test_score': array([0.52375, 0.52375, 0.5225 , 0.5225 , 0.52625, 0.52625, 0.51625,\n",
      "       0.51625, 0.56875, 0.56875, 0.545  , 0.545  , 0.525  , 0.525  ]), 'std_test_score': array([0.0181573 , 0.0181573 , 0.02358495, 0.02358495, 0.0143069 ,\n",
      "       0.0143069 , 0.0240767 , 0.0240767 , 0.01948557, 0.01948557,\n",
      "       0.01369306, 0.01369306, 0.01274755, 0.01274755]), 'rank_test_score': array([ 9,  9, 11, 11,  5,  5, 13, 13,  1,  1,  3,  3,  7,  7])} \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Uncomment below to see the results of hyperparameter tuning\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_estimator_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_score_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.best_params_, \"\\n\")\n",
    "print (\"-\"*100)\n",
    "print(gscv.cv_results_, \"\\n\")\n",
    "print (\"-\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n",
      "confusion matrix\n",
      "[[14 14 15]\n",
      " [ 7 62 14]\n",
      " [ 5 39 30]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.33      0.41        43\n",
      "           1       0.54      0.75      0.63        83\n",
      "           2       0.51      0.41      0.45        74\n",
      "\n",
      "    accuracy                           0.53       200\n",
      "   macro avg       0.53      0.49      0.49       200\n",
      "weighted avg       0.53      0.53      0.51       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print(\"confusion matrix\")\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))\n",
    "# TN,FP,FN,TP = metrics.confusion_matrix(y_true=ytest, y_pred=ypred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
